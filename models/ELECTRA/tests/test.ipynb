{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False,  True,  True, False, False, False,  True, False]])\n",
      "tensor([[ True,  True,  True, False, False, False, False, False, False]])\n",
      "tensor([[False, False, False,  True,  True, False, False,  True, False]])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def prob_mask_like(t, prob):\n",
    "    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n",
    "\n",
    "def mask_with_tokens(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    return mask\n",
    "\n",
    "def get_mask_subset_with_prob(mask, prob):\n",
    "    batch, seq_len, device = *mask.shape, mask.device\n",
    "    max_masked = math.ceil(prob * seq_len)\n",
    "\n",
    "    num_tokens = mask.sum(dim=-1, keepdim=True)\n",
    "    mask_excess = (mask.cumsum(dim=-1) > (num_tokens * prob).ceil())\n",
    "    mask_excess = mask_excess[:, :max_masked]\n",
    "\n",
    "    rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)\n",
    "    _, sampled_indices = rand.topk(max_masked, dim=-1)\n",
    "    sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)\n",
    "\n",
    "    new_mask = torch.zeros((batch, seq_len + 1), device=device)\n",
    "    new_mask.scatter_(-1, sampled_indices, 1)\n",
    "    return new_mask[:, 1:].bool()\n",
    "\n",
    "\n",
    "replace_prob = 0.3\n",
    "mask_prob = 0.3\n",
    "\n",
    "input = torch.tensor([[1, 2, 3, 4, 5, 9, 11, 13, 15]])\n",
    "\n",
    "replace_prob = prob_mask_like(input, replace_prob)\n",
    "\n",
    "print(replace_prob)\n",
    "\n",
    "mask_ignore_token_ids = set([1, 2, 3])\n",
    "\n",
    "no_mask = mask_with_tokens(input, mask_ignore_token_ids)\n",
    "mask = get_mask_subset_with_prob(~no_mask, mask_prob)\n",
    "\n",
    "print(no_mask)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_var_seq(var_list: torch.Tensor, indicate: torch.Tensor, device):\n",
    "        # indicate.shape = (batch, max_len)\n",
    "        result = []\n",
    "        mask_ind = []\n",
    "        var_len = var_list.size(0)\n",
    "\n",
    "        for batch in indicate:\n",
    "            seq = []\n",
    "            mask = []\n",
    "            for i, item in enumerate(batch):\n",
    "                if item == 3:\n",
    "                        seq.append(torch.full_like(var_list, 3, device=device))\n",
    "                        mask.extend(range(i*var_len, i*var_len + var_len, 1))\n",
    "                else:\n",
    "                    seq.append(var_list)\n",
    "\n",
    "            seq = torch.cat(seq, dim=0)\n",
    "            result.append(seq)\n",
    "            mask_ind.append(mask)\n",
    "            \n",
    "        result = torch.stack(result, dim=0)\n",
    "        mask_ind = torch.tensor(mask_ind)\n",
    "        return result, mask_ind\n",
    "\n",
    "var_list = torch.tensor([4, 5, 6, 7, 8, 9])\n",
    "indicate = torch.tensor([4, 5, 3, 3, 8, 9, 3, 11]).unsqueeze(0)\n",
    "\n",
    "result, mask_ind = get_var_seq(var_list, indicate, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5, 6, 7, 8, 9, 4, 5, 6, 7, 8, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         4, 5, 6, 7, 8, 9, 4, 5, 6, 7, 8, 9, 3, 3, 3, 3, 3, 3, 4, 5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 36, 37, 38, 39, 40, 41]])\n"
     ]
    }
   ],
   "source": [
    "print(mask_ind)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
