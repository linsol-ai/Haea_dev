{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys,os\n",
    "import torch\n",
    "current_directory = os.getcwd()\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(current_directory))))))\n",
    "from datasets.weather_bench import WeatherDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 불러오는 중...\n",
      "==== LOAD DATASET ====\n",
      " <xarray.Dataset>\n",
      "Dimensions:                   (time: 7305, latitude: 28, longitude: 28,\n",
      "                               level: 13)\n",
      "Coordinates:\n",
      "  * latitude                  (latitude) float32 39.0 38.75 38.5 ... 32.5 32.25\n",
      "  * level                     (level) int64 50 100 150 200 ... 700 850 925 1000\n",
      "  * longitude                 (longitude) float32 124.2 124.5 ... 130.8 131.0\n",
      "  * time                      (time) datetime64[ns] 2016-12-31 ... 2021-12-31\n",
      "Data variables: (12/14)\n",
      "    10m_u_component_of_wind   (time, latitude, longitude) float32 ...\n",
      "    10m_v_component_of_wind   (time, latitude, longitude) float32 ...\n",
      "    2m_temperature            (time, latitude, longitude) float32 ...\n",
      "    geopotential              (time, level, latitude, longitude) float32 ...\n",
      "    mean_sea_level_pressure   (time, latitude, longitude) float32 ...\n",
      "    sea_surface_temperature   (time, latitude, longitude) float32 ...\n",
      "    ...                        ...\n",
      "    total_cloud_cover         (time, latitude, longitude) float32 ...\n",
      "    total_precipitation_24hr  (time, latitude, longitude) float32 ...\n",
      "    total_precipitation_6hr   (time, latitude, longitude) float32 ...\n",
      "    u_component_of_wind       (time, level, latitude, longitude) float32 ...\n",
      "    v_component_of_wind       (time, level, latitude, longitude) float32 ...\n",
      "    vertical_velocity         (time, level, latitude, longitude) float32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing futures: 14it [00:13,  1.04it/s]\n",
      "Processing futures: 2it [00:01,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.61906 sec\n",
      "==== LOAD DATASET ====\n",
      " <xarray.Dataset>\n",
      "Dimensions:                   (time: 7305, longitude: 14, latitude: 33,\n",
      "                               level: 13)\n",
      "Coordinates:\n",
      "  * latitude                  (latitude) float64 21.0 22.5 24.0 ... 67.5 69.0\n",
      "  * level                     (level) int64 50 100 150 200 ... 700 850 925 1000\n",
      "  * longitude                 (longitude) float64 121.5 123.0 ... 139.5 141.0\n",
      "  * time                      (time) datetime64[ns] 2016-12-31 ... 2021-12-31\n",
      "Data variables: (12/14)\n",
      "    10m_u_component_of_wind   (time, longitude, latitude) float32 ...\n",
      "    10m_v_component_of_wind   (time, longitude, latitude) float32 ...\n",
      "    2m_temperature            (time, longitude, latitude) float32 ...\n",
      "    geopotential              (time, level, longitude, latitude) float32 ...\n",
      "    mean_sea_level_pressure   (time, longitude, latitude) float32 ...\n",
      "    sea_surface_temperature   (time, longitude, latitude) float32 ...\n",
      "    ...                        ...\n",
      "    total_cloud_cover         (time, longitude, latitude) float32 ...\n",
      "    total_precipitation_24hr  (time, longitude, latitude) float32 ...\n",
      "    total_precipitation_6hr   (time, longitude, latitude) float32 ...\n",
      "    u_component_of_wind       (time, level, longitude, latitude) float32 ...\n",
      "    v_component_of_wind       (time, level, longitude, latitude) float32 ...\n",
      "    vertical_velocity         (time, level, longitude, latitude) float32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing futures: 14it [00:10,  1.33it/s]\n",
      "Processing futures: 2it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.11322 sec\n",
      "==== LOAD DATASET ====\n",
      " <xarray.Dataset>\n",
      "Dimensions:                   (time: 7305, longitude: 17, latitude: 12,\n",
      "                               level: 13)\n",
      "Coordinates:\n",
      "  * latitude                  (latitude) float64 2.903 8.71 ... 60.97 66.77\n",
      "  * level                     (level) int64 50 100 150 200 ... 700 850 925 1000\n",
      "  * longitude                 (longitude) float64 90.0 95.62 ... 174.4 180.0\n",
      "  * time                      (time) datetime64[ns] 2016-12-31 ... 2021-12-31\n",
      "Data variables: (12/14)\n",
      "    10m_u_component_of_wind   (time, longitude, latitude) float32 ...\n",
      "    10m_v_component_of_wind   (time, longitude, latitude) float32 ...\n",
      "    2m_temperature            (time, longitude, latitude) float32 ...\n",
      "    geopotential              (time, level, longitude, latitude) float32 ...\n",
      "    mean_sea_level_pressure   (time, longitude, latitude) float32 ...\n",
      "    sea_surface_temperature   (time, longitude, latitude) float32 ...\n",
      "    ...                        ...\n",
      "    total_cloud_cover         (time, longitude, latitude) float32 ...\n",
      "    total_precipitation_24hr  (time, longitude, latitude) float32 ...\n",
      "    total_precipitation_6hr   (time, longitude, latitude) float32 ...\n",
      "    u_component_of_wind       (time, level, longitude, latitude) float32 ...\n",
      "    v_component_of_wind       (time, level, longitude, latitude) float32 ...\n",
      "    vertical_velocity         (time, level, longitude, latitude) float32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing futures: 14it [00:09,  1.41it/s]\n",
      "Processing futures: 2it [00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.23150 sec\n",
      "======= RESULT SHAPE =======\n",
      "result_dataset.shape:  torch.Size([7305, 100, 1450])\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "device = torch.device(device)\n",
    "\n",
    "weather = WeatherDataset(0, device=device, normalize=True)\n",
    "# dataset.shape:  torch.Size([7309, 100, 1450])\n",
    "original = weather.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models.VariableAnalyzer.datasets.dataset import CustomDataset\n",
    "dataset = CustomDataset(original, 4 * 7, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getdata:  0.00096 sec\n",
      "getdata:  0.00385 sec\n",
      "res:  0.00560 sec\n",
      "tensor([[0.2695, 0.2715, 0.2703,  ..., 0.7818, 0.6788, 0.5188],\n",
      "        [0.1810, 0.1773, 0.1726,  ..., 0.4673, 0.4184, 0.3465],\n",
      "        [0.1628, 0.1569, 0.1506,  ..., 0.3565, 0.3355, 0.2872],\n",
      "        ...,\n",
      "        [0.3319, 0.3644, 0.3936,  ..., 0.2570, 0.4454, 0.6686],\n",
      "        [0.2312, 0.4194, 0.4887,  ..., 0.2219, 0.3896, 0.6130],\n",
      "        [0.3171, 0.0150, 0.0218,  ..., 0.1309, 0.2664, 0.4330]])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "dataloader = DataLoader(dataset, 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n",
      "torch.Size([32, 2900, 1450])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/workspace/Haea/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/workspace/Haea/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/workspace/Haea/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/workspace/Haea/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/workspace/Haea/models/VariableAnalyzer/datasets/dataset.py:44\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     43\u001b[0m     src, tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_inc[item]\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mconcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data(src), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/workspace/Haea/models/VariableAnalyzer/datasets/dataset.py:28\u001b[0m, in \u001b[0;36mCustomDataset.get_data\u001b[0;34m(self, indicate)\u001b[0m\n\u001b[1;32m     25\u001b[0m         dataset\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[t])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# dataset.shape = (time_len, var, hidden)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dataset\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Haea/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from models.VariableAnalyzer.models.model import VariableAnalyzer\n",
    "\n",
    "model = VariableAnalyzer(100, 4 * 7, 1450, 25, 3, 3)\n",
    "print(model.get_tgt_mask(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(0, 3, None), 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m             time_seq\u001b[38;5;241m.\u001b[39mextend(seq)\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor([time_seq \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))])\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_time_seq(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "File \u001b[0;32m/workspace/Haea/models/VariableAnalyzer/datasets/dataset.py:44\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item)\n\u001b[0;32m---> 44\u001b[0m     src, tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_inc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data(src), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data(tgt)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "def get_time_seq(src: torch.Tensor):\n",
    "        time_seq = []\n",
    "        for i in range(4 * 7):\n",
    "            seq = [i for _ in range(100)]\n",
    "            time_seq.extend(seq)\n",
    "        return torch.tensor([time_seq for _ in range(src.size(0))])\n",
    "\n",
    "\n",
    "print(get_time_seq(dataset[0:3, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
