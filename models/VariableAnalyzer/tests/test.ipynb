{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys,os\n",
    "import torch\n",
    "current_directory = os.getcwd()\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(current_directory))))))\n",
    "from datasets.weather_bench import WeatherDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 불러오는 중...\n",
      "==== LOAD DATASET ====\n",
      " <xarray.Dataset>\n",
      "Dimensions:                   (time: 7305, latitude: 28, longitude: 28,\n",
      "                               level: 13)\n",
      "Coordinates:\n",
      "  * latitude                  (latitude) float32 39.0 38.75 38.5 ... 32.5 32.25\n",
      "  * level                     (level) int64 50 100 150 200 ... 700 850 925 1000\n",
      "  * longitude                 (longitude) float32 124.2 124.5 ... 130.8 131.0\n",
      "  * time                      (time) datetime64[ns] 2016-12-31 ... 2021-12-31\n",
      "Data variables: (12/14)\n",
      "    10m_u_component_of_wind   (time, latitude, longitude) float32 ...\n",
      "    10m_v_component_of_wind   (time, latitude, longitude) float32 ...\n",
      "    2m_temperature            (time, latitude, longitude) float32 ...\n",
      "    geopotential              (time, level, latitude, longitude) float32 ...\n",
      "    mean_sea_level_pressure   (time, latitude, longitude) float32 ...\n",
      "    sea_surface_temperature   (time, latitude, longitude) float32 ...\n",
      "    ...                        ...\n",
      "    total_cloud_cover         (time, latitude, longitude) float32 ...\n",
      "    total_precipitation_24hr  (time, latitude, longitude) float32 ...\n",
      "    total_precipitation_6hr   (time, latitude, longitude) float32 ...\n",
      "    u_component_of_wind       (time, level, latitude, longitude) float32 ...\n",
      "    v_component_of_wind       (time, level, latitude, longitude) float32 ...\n",
      "    vertical_velocity         (time, level, latitude, longitude) float32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing futures: 14it [00:13,  1.04it/s]\n",
      "Processing futures: 2it [00:01,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.61906 sec\n",
      "==== LOAD DATASET ====\n",
      " <xarray.Dataset>\n",
      "Dimensions:                   (time: 7305, longitude: 14, latitude: 33,\n",
      "                               level: 13)\n",
      "Coordinates:\n",
      "  * latitude                  (latitude) float64 21.0 22.5 24.0 ... 67.5 69.0\n",
      "  * level                     (level) int64 50 100 150 200 ... 700 850 925 1000\n",
      "  * longitude                 (longitude) float64 121.5 123.0 ... 139.5 141.0\n",
      "  * time                      (time) datetime64[ns] 2016-12-31 ... 2021-12-31\n",
      "Data variables: (12/14)\n",
      "    10m_u_component_of_wind   (time, longitude, latitude) float32 ...\n",
      "    10m_v_component_of_wind   (time, longitude, latitude) float32 ...\n",
      "    2m_temperature            (time, longitude, latitude) float32 ...\n",
      "    geopotential              (time, level, longitude, latitude) float32 ...\n",
      "    mean_sea_level_pressure   (time, longitude, latitude) float32 ...\n",
      "    sea_surface_temperature   (time, longitude, latitude) float32 ...\n",
      "    ...                        ...\n",
      "    total_cloud_cover         (time, longitude, latitude) float32 ...\n",
      "    total_precipitation_24hr  (time, longitude, latitude) float32 ...\n",
      "    total_precipitation_6hr   (time, longitude, latitude) float32 ...\n",
      "    u_component_of_wind       (time, level, longitude, latitude) float32 ...\n",
      "    v_component_of_wind       (time, level, longitude, latitude) float32 ...\n",
      "    vertical_velocity         (time, level, longitude, latitude) float32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing futures: 14it [00:10,  1.33it/s]\n",
      "Processing futures: 2it [00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.11322 sec\n",
      "==== LOAD DATASET ====\n",
      " <xarray.Dataset>\n",
      "Dimensions:                   (time: 7305, longitude: 17, latitude: 12,\n",
      "                               level: 13)\n",
      "Coordinates:\n",
      "  * latitude                  (latitude) float64 2.903 8.71 ... 60.97 66.77\n",
      "  * level                     (level) int64 50 100 150 200 ... 700 850 925 1000\n",
      "  * longitude                 (longitude) float64 90.0 95.62 ... 174.4 180.0\n",
      "  * time                      (time) datetime64[ns] 2016-12-31 ... 2021-12-31\n",
      "Data variables: (12/14)\n",
      "    10m_u_component_of_wind   (time, longitude, latitude) float32 ...\n",
      "    10m_v_component_of_wind   (time, longitude, latitude) float32 ...\n",
      "    2m_temperature            (time, longitude, latitude) float32 ...\n",
      "    geopotential              (time, level, longitude, latitude) float32 ...\n",
      "    mean_sea_level_pressure   (time, longitude, latitude) float32 ...\n",
      "    sea_surface_temperature   (time, longitude, latitude) float32 ...\n",
      "    ...                        ...\n",
      "    total_cloud_cover         (time, longitude, latitude) float32 ...\n",
      "    total_precipitation_24hr  (time, longitude, latitude) float32 ...\n",
      "    total_precipitation_6hr   (time, longitude, latitude) float32 ...\n",
      "    u_component_of_wind       (time, level, longitude, latitude) float32 ...\n",
      "    v_component_of_wind       (time, level, longitude, latitude) float32 ...\n",
      "    vertical_velocity         (time, level, longitude, latitude) float32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing futures: 14it [00:09,  1.41it/s]\n",
      "Processing futures: 2it [00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.23150 sec\n",
      "======= RESULT SHAPE =======\n",
      "result_dataset.shape:  torch.Size([7305, 100, 1450])\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "device = torch.device(device)\n",
    "\n",
    "weather = WeatherDataset(0, device=device, normalize=True)\n",
    "# dataset.shape:  torch.Size([7309, 100, 1450])\n",
    "original = weather.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models.VariableAnalyzer.datasets.dataset import CustomDataset\n",
    "dataset = CustomDataset(original, 4 * 7, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2695, 0.2715, 0.2703,  ..., 0.7818, 0.6788, 0.5188],\n",
      "        [0.1810, 0.1773, 0.1726,  ..., 0.4673, 0.4184, 0.3465],\n",
      "        [0.1628, 0.1569, 0.1506,  ..., 0.3565, 0.3355, 0.2872],\n",
      "        ...,\n",
      "        [0.3319, 0.3644, 0.3936,  ..., 0.2570, 0.4454, 0.6686],\n",
      "        [0.2312, 0.4194, 0.4887,  ..., 0.2219, 0.3896, 0.6130],\n",
      "        [0.3171, 0.0150, 0.0218,  ..., 0.1309, 0.2664, 0.4330]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "dataloader = DataLoader(dataset, 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 2900, 1450])\n",
      "1 torch.Size([32, 2900, 1450])\n",
      "2 torch.Size([32, 2900, 1450])\n",
      "3 torch.Size([32, 2900, 1450])\n",
      "4 torch.Size([32, 2900, 1450])\n",
      "5 torch.Size([32, 2900, 1450])\n",
      "6 torch.Size([32, 2900, 1450])\n",
      "7 torch.Size([32, 2900, 1450])\n",
      "8 torch.Size([32, 2900, 1450])\n",
      "9 torch.Size([32, 2900, 1450])\n",
      "10 torch.Size([32, 2900, 1450])\n",
      "11 torch.Size([32, 2900, 1450])\n",
      "12 torch.Size([32, 2900, 1450])\n",
      "13 torch.Size([32, 2900, 1450])\n",
      "14 torch.Size([32, 2900, 1450])\n",
      "15 torch.Size([32, 2900, 1450])\n",
      "16 torch.Size([32, 2900, 1450])\n",
      "17 torch.Size([32, 2900, 1450])\n",
      "18 torch.Size([32, 2900, 1450])\n",
      "19 torch.Size([32, 2900, 1450])\n",
      "20 torch.Size([32, 2900, 1450])\n",
      "21 torch.Size([32, 2900, 1450])\n",
      "22 torch.Size([32, 2900, 1450])\n",
      "23 torch.Size([32, 2900, 1450])\n",
      "24 torch.Size([32, 2900, 1450])\n",
      "25 torch.Size([32, 2900, 1450])\n",
      "26 torch.Size([32, 2900, 1450])\n",
      "27 torch.Size([32, 2900, 1450])\n",
      "28 torch.Size([32, 2900, 1450])\n",
      "29 torch.Size([32, 2900, 1450])\n",
      "30 torch.Size([32, 2900, 1450])\n",
      "31 torch.Size([32, 2900, 1450])\n",
      "32 torch.Size([32, 2900, 1450])\n",
      "33 torch.Size([32, 2900, 1450])\n",
      "34 torch.Size([32, 2900, 1450])\n",
      "35 torch.Size([32, 2900, 1450])\n",
      "36 torch.Size([32, 2900, 1450])\n",
      "37 torch.Size([32, 2900, 1450])\n",
      "38 torch.Size([32, 2900, 1450])\n",
      "39 torch.Size([32, 2900, 1450])\n",
      "40 torch.Size([32, 2900, 1450])\n",
      "41 torch.Size([32, 2900, 1450])\n",
      "42 torch.Size([32, 2900, 1450])\n",
      "43 torch.Size([32, 2900, 1450])\n",
      "44 torch.Size([32, 2900, 1450])\n",
      "45 torch.Size([32, 2900, 1450])\n",
      "46 torch.Size([32, 2900, 1450])\n",
      "47 torch.Size([32, 2900, 1450])\n",
      "48 torch.Size([32, 2900, 1450])\n",
      "49 torch.Size([32, 2900, 1450])\n",
      "50 torch.Size([32, 2900, 1450])\n",
      "51 torch.Size([32, 2900, 1450])\n",
      "52 torch.Size([32, 2900, 1450])\n",
      "53 torch.Size([32, 2900, 1450])\n",
      "54 torch.Size([32, 2900, 1450])\n",
      "55 torch.Size([32, 2900, 1450])\n",
      "56 torch.Size([32, 2900, 1450])\n",
      "57 torch.Size([32, 2900, 1450])\n",
      "58 torch.Size([32, 2900, 1450])\n",
      "59 torch.Size([32, 2900, 1450])\n",
      "60 torch.Size([32, 2900, 1450])\n",
      "61 torch.Size([32, 2900, 1450])\n",
      "62 torch.Size([32, 2900, 1450])\n",
      "63 torch.Size([32, 2900, 1450])\n",
      "64 torch.Size([32, 2900, 1450])\n",
      "65 torch.Size([32, 2900, 1450])\n",
      "66 torch.Size([32, 2900, 1450])\n",
      "67 torch.Size([32, 2900, 1450])\n",
      "68 torch.Size([32, 2900, 1450])\n",
      "69 torch.Size([32, 2900, 1450])\n",
      "70 torch.Size([32, 2900, 1450])\n",
      "71 torch.Size([32, 2900, 1450])\n",
      "72 torch.Size([32, 2900, 1450])\n",
      "73 torch.Size([32, 2900, 1450])\n",
      "74 torch.Size([32, 2900, 1450])\n",
      "75 torch.Size([32, 2900, 1450])\n",
      "76 torch.Size([32, 2900, 1450])\n",
      "77 torch.Size([32, 2900, 1450])\n",
      "78 torch.Size([32, 2900, 1450])\n",
      "79 torch.Size([32, 2900, 1450])\n",
      "80 torch.Size([32, 2900, 1450])\n",
      "81 torch.Size([32, 2900, 1450])\n",
      "82 torch.Size([32, 2900, 1450])\n",
      "83 torch.Size([32, 2900, 1450])\n",
      "84 torch.Size([32, 2900, 1450])\n",
      "85 torch.Size([32, 2900, 1450])\n",
      "86 torch.Size([32, 2900, 1450])\n",
      "87 torch.Size([32, 2900, 1450])\n",
      "88 torch.Size([32, 2900, 1450])\n",
      "89 torch.Size([32, 2900, 1450])\n",
      "90 torch.Size([32, 2900, 1450])\n",
      "91 torch.Size([32, 2900, 1450])\n",
      "92 torch.Size([32, 2900, 1450])\n",
      "93 torch.Size([32, 2900, 1450])\n",
      "94 torch.Size([32, 2900, 1450])\n",
      "95 torch.Size([32, 2900, 1450])\n",
      "96 torch.Size([32, 2900, 1450])\n",
      "97 torch.Size([32, 2900, 1450])\n",
      "98 torch.Size([32, 2900, 1450])\n",
      "99 torch.Size([32, 2900, 1450])\n",
      "100 torch.Size([32, 2900, 1450])\n",
      "101 torch.Size([32, 2900, 1450])\n",
      "102 torch.Size([32, 2900, 1450])\n",
      "103 torch.Size([32, 2900, 1450])\n",
      "104 torch.Size([32, 2900, 1450])\n",
      "105 torch.Size([32, 2900, 1450])\n",
      "106 torch.Size([32, 2900, 1450])\n",
      "107 torch.Size([32, 2900, 1450])\n",
      "108 torch.Size([32, 2900, 1450])\n",
      "109 torch.Size([32, 2900, 1450])\n",
      "110 torch.Size([32, 2900, 1450])\n",
      "111 torch.Size([32, 2900, 1450])\n",
      "112 torch.Size([32, 2900, 1450])\n",
      "113 torch.Size([32, 2900, 1450])\n",
      "114 torch.Size([32, 2900, 1450])\n",
      "115 torch.Size([32, 2900, 1450])\n",
      "116 torch.Size([32, 2900, 1450])\n",
      "117 torch.Size([32, 2900, 1450])\n",
      "118 torch.Size([32, 2900, 1450])\n",
      "119 torch.Size([32, 2900, 1450])\n",
      "120 torch.Size([32, 2900, 1450])\n",
      "121 torch.Size([32, 2900, 1450])\n",
      "122 torch.Size([32, 2900, 1450])\n",
      "123 torch.Size([32, 2900, 1450])\n",
      "124 torch.Size([32, 2900, 1450])\n",
      "125 torch.Size([32, 2900, 1450])\n",
      "126 torch.Size([32, 2900, 1450])\n",
      "127 torch.Size([32, 2900, 1450])\n",
      "128 torch.Size([32, 2900, 1450])\n",
      "129 torch.Size([32, 2900, 1450])\n",
      "130 torch.Size([32, 2900, 1450])\n",
      "131 torch.Size([32, 2900, 1450])\n",
      "132 torch.Size([32, 2900, 1450])\n",
      "133 torch.Size([32, 2900, 1450])\n",
      "134 torch.Size([32, 2900, 1450])\n",
      "135 torch.Size([32, 2900, 1450])\n",
      "136 torch.Size([32, 2900, 1450])\n",
      "137 torch.Size([32, 2900, 1450])\n",
      "138 torch.Size([32, 2900, 1450])\n",
      "139 torch.Size([32, 2900, 1450])\n",
      "140 torch.Size([32, 2900, 1450])\n",
      "141 torch.Size([32, 2900, 1450])\n",
      "142 torch.Size([32, 2900, 1450])\n",
      "143 torch.Size([32, 2900, 1450])\n",
      "144 torch.Size([32, 2900, 1450])\n",
      "145 torch.Size([32, 2900, 1450])\n",
      "146 torch.Size([32, 2900, 1450])\n",
      "147 torch.Size([32, 2900, 1450])\n",
      "148 torch.Size([32, 2900, 1450])\n",
      "149 torch.Size([32, 2900, 1450])\n",
      "150 torch.Size([32, 2900, 1450])\n",
      "151 torch.Size([32, 2900, 1450])\n",
      "152 torch.Size([32, 2900, 1450])\n",
      "153 torch.Size([32, 2900, 1450])\n",
      "154 torch.Size([32, 2900, 1450])\n",
      "155 torch.Size([32, 2900, 1450])\n",
      "156 torch.Size([32, 2900, 1450])\n",
      "157 torch.Size([32, 2900, 1450])\n",
      "158 torch.Size([32, 2900, 1450])\n",
      "159 torch.Size([32, 2900, 1450])\n",
      "160 torch.Size([32, 2900, 1450])\n",
      "161 torch.Size([32, 2900, 1450])\n",
      "162 torch.Size([32, 2900, 1450])\n",
      "163 torch.Size([32, 2900, 1450])\n",
      "164 torch.Size([32, 2900, 1450])\n",
      "165 torch.Size([32, 2900, 1450])\n",
      "166 torch.Size([32, 2900, 1450])\n",
      "167 torch.Size([32, 2900, 1450])\n",
      "168 torch.Size([32, 2900, 1450])\n",
      "169 torch.Size([32, 2900, 1450])\n",
      "170 torch.Size([32, 2900, 1450])\n",
      "171 torch.Size([32, 2900, 1450])\n",
      "172 torch.Size([32, 2900, 1450])\n",
      "173 torch.Size([32, 2900, 1450])\n",
      "174 torch.Size([32, 2900, 1450])\n",
      "175 torch.Size([32, 2900, 1450])\n",
      "176 torch.Size([32, 2900, 1450])\n",
      "177 torch.Size([32, 2900, 1450])\n",
      "178 torch.Size([32, 2900, 1450])\n",
      "179 torch.Size([32, 2900, 1450])\n",
      "180 torch.Size([32, 2900, 1450])\n",
      "181 torch.Size([32, 2900, 1450])\n",
      "182 torch.Size([32, 2900, 1450])\n",
      "183 torch.Size([32, 2900, 1450])\n",
      "184 torch.Size([32, 2900, 1450])\n",
      "185 torch.Size([32, 2900, 1450])\n",
      "186 torch.Size([32, 2900, 1450])\n",
      "187 torch.Size([32, 2900, 1450])\n",
      "188 torch.Size([32, 2900, 1450])\n",
      "189 torch.Size([32, 2900, 1450])\n",
      "190 torch.Size([32, 2900, 1450])\n",
      "191 torch.Size([32, 2900, 1450])\n",
      "192 torch.Size([32, 2900, 1450])\n",
      "193 torch.Size([32, 2900, 1450])\n",
      "194 torch.Size([32, 2900, 1450])\n",
      "195 torch.Size([32, 2900, 1450])\n",
      "196 torch.Size([32, 2900, 1450])\n",
      "197 torch.Size([32, 2900, 1450])\n",
      "198 torch.Size([32, 2900, 1450])\n",
      "199 torch.Size([32, 2900, 1450])\n",
      "200 torch.Size([32, 2900, 1450])\n",
      "201 torch.Size([32, 2900, 1450])\n",
      "202 torch.Size([32, 2900, 1450])\n",
      "203 torch.Size([32, 2900, 1450])\n",
      "204 torch.Size([32, 2900, 1450])\n",
      "205 torch.Size([32, 2900, 1450])\n",
      "206 torch.Size([32, 2900, 1450])\n",
      "207 torch.Size([32, 2900, 1450])\n",
      "208 torch.Size([32, 2900, 1450])\n",
      "209 torch.Size([32, 2900, 1450])\n",
      "210 torch.Size([32, 2900, 1450])\n",
      "211 torch.Size([32, 2900, 1450])\n",
      "212 torch.Size([32, 2900, 1450])\n",
      "213 torch.Size([32, 2900, 1450])\n",
      "214 torch.Size([32, 2900, 1450])\n",
      "215 torch.Size([32, 2900, 1450])\n",
      "216 torch.Size([32, 2900, 1450])\n",
      "217 torch.Size([32, 2900, 1450])\n",
      "218 torch.Size([32, 2900, 1450])\n",
      "219 torch.Size([32, 2900, 1450])\n",
      "220 torch.Size([32, 2900, 1450])\n",
      "221 torch.Size([32, 2900, 1450])\n",
      "222 torch.Size([32, 2900, 1450])\n",
      "223 torch.Size([32, 2900, 1450])\n",
      "224 torch.Size([32, 2900, 1450])\n",
      "225 torch.Size([32, 2900, 1450])\n",
      "226 torch.Size([32, 2900, 1450])\n",
      "227 torch.Size([13, 2900, 1450])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    print(i, batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Haea/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., 27., 27., 27.]],\n",
      "\n",
      "        [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., 27., 27., 27.]],\n",
      "\n",
      "        [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., 27., 27., 27.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., 27., 27., 27.]],\n",
      "\n",
      "        [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., 27., 27., 27.]],\n",
      "\n",
      "        [[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         ...,\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf,  ..., 27., 27., 27.]]])\n"
     ]
    }
   ],
   "source": [
    "from models.VariableAnalyzer.models.model import VariableAnalyzer\n",
    "\n",
    "model = VariableAnalyzer(100, 4 * 7, 1450, 25, 3, 3)\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    print(model.get_tgt_mask(batch))\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def create_custom_lower_triangular_matrix(size, interval):\n",
    "    # 모든 요소가 0인 행렬 생성\n",
    "    matrix = torch.zeros(size, size)\n",
    "    \n",
    "    # 대각선을 따라 interval 간격으로 1 채우기\n",
    "    for i in range(0, size):\n",
    "        for j in range(0, min(interval*(i+1), size)):\n",
    "            matrix[i, j] = 1\n",
    "    \n",
    "    print(matrix)\n",
    "    # Lower triangular matrix 반환\n",
    "    return torch.tril(matrix)\n",
    "\n",
    "\n",
    "\n",
    "size = 5\n",
    "interval = 2\n",
    "custom_matrix = create_custom_lower_triangular_matrix(size, interval)\n",
    "print(custom_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(slice(0, 3, None), 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m             time_seq\u001b[38;5;241m.\u001b[39mextend(seq)\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor([time_seq \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))])\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_time_seq(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "File \u001b[0;32m/workspace/Haea/models/VariableAnalyzer/datasets/dataset.py:44\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item)\n\u001b[0;32m---> 44\u001b[0m     src, tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_inc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data(src), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data(tgt)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "def get_time_seq(src: torch.Tensor):\n",
    "        time_seq = []\n",
    "        for i in range(4 * 7):\n",
    "            seq = [i for _ in range(100)]\n",
    "            time_seq.extend(seq)\n",
    "        return torch.tensor([time_seq for _ in range(src.size(0))])\n",
    "\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    print()\n",
    "    if i == 0:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
