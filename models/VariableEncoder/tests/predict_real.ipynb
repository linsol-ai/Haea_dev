{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "from pydantic import ValidationError\n",
    "from typing import List, Tuple\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(os.getcwd()))))))\n",
    "from datasets.weather_bench import WeatherDataset\n",
    "from models.VariableEncoder.datasets.dataset import CustomDataset\n",
    "from models.VariableEncoder.training.configs import TrainingConfig\n",
    "from models.VariableEncoder.training.configs import TrainingRunConfig\n",
    "\n",
    "\n",
    "def get_normal_dataset(config: TrainingConfig) -> Tuple[CustomDataset, torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "    device = torch.device(device)\n",
    "\n",
    "    vars = config.air_variable + config.surface_variable + config.only_input_variable + config.constant_variable\n",
    "\n",
    "    weather = WeatherDataset(config.train_start, config.train_end, device=device, download_variables=vars, download_levels=config.levels)\n",
    "    # dataset.shape:  torch.Size([7309, 100, 1450])\n",
    "    \n",
    "    source, mean_std, var_vocab = weather.load_one(config.air_variable, config.surface_variable, config.only_input_variable, \n",
    "                                        config.constant_variable, level=config.levels)\n",
    "    src_var_list = var_vocab.get_code(vars)\n",
    "    tgt_var_list = var_vocab.get_code(config.air_variable + config.surface_variable)\n",
    "\n",
    "    dataset = CustomDataset(source, config.src_time_len, config.tgt_time_len, n_only_input=len(config.only_input_variable)+len(config.constant_variable))\n",
    "    return dataset, mean_std, (src_var_list, tgt_var_list)\n",
    "\n",
    "\n",
    "config_path = os.path.join(os.path.dirname(os.getcwd()), 'configs/train_config.yaml')\n",
    "\n",
    "try:\n",
    "    with open(config_path) as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "    config: TrainingRunConfig = TrainingRunConfig.parse_obj(config_dict)\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Config file {config_path} does not exist. Exiting.\")\n",
    "except yaml.YAMLError:\n",
    "    logging.error(f\"Config file {config_path} is not valid YAML. Exiting.\")\n",
    "except ValidationError as e:\n",
    "    logging.error(f\"Config file {config_path} is not valid. Exiting.\\n{e}\")\n",
    "\n",
    "\n",
    "dataset, mean_std, var_list = get_normal_dataset(config.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize(loss: torch.Tensor, title, isAIR = False):\n",
    "    if isAIR:\n",
    "        loss = loss.swapaxes(0, 1)\n",
    "    print(loss.shape)\n",
    "    plt.plot(loss, label=\"rmse loss\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: TrainModule, src: torch.Tensor, label: torch.Tensor, device):\n",
    "    model.model.eval()\n",
    "    model.setting()\n",
    "\n",
    "    src = src.to(device).unsqueeze(0)\n",
    "    label = label.to(device).unsqueeze(0)\n",
    "    src = src + positional_encoding(src.size(0), config.training.src_time_len, var_list[0].size(0), src.size(-1), device)\n",
    "    tgt = torch.zeros(label.size(0), 1, label.size(2), device=device)\n",
    "    tgt = torch.cat([tgt, label[:, :var_list[1].size(0)]], dim=1)\n",
    "\n",
    "    for i in range(1, config.training.tgt_time_len+1):\n",
    "        pos = positional_encoding(tgt.size(0), i, var_list[1].size(0), tgt.size(-1), device, has_special_token=True)\n",
    "        src_seq, tgt_seq = get_var_seq(var_list[0], var_list[1], config.training.src_time_len, i, src.size(0))\n",
    "        tgt_mask = get_tgt_mask(var_list[1].size(0), i).to(device)\n",
    "\n",
    "        tgt = tgt + pos\n",
    "        src_seq = src_seq.to(device)\n",
    "        tgt_seq = tgt_seq.to(device)\n",
    "        predict = model.model(src, tgt, src_seq, tgt_seq, tgt_mask)\n",
    "        # predict.shape = (batch, i * var + 1, hidden)\n",
    "        print(predict.shape)\n",
    "        tgt = predict\n",
    "    \n",
    "    tgt = tgt[:, :-1]\n",
    "    \n",
    "    tgt = tgt.view(tgt.size(0), config.training.tgt_time_len, var_list[1].size(0), tgt.size(-1))\n",
    "    label = label.view(tgt.size(0), config.training.tgt_time_len, var_list[1].size(0), tgt.size(-1))\n",
    "    \n",
    "    loss = model.calculate_sqare_loss(tgt, label)\n",
    "    # loss.shape = (batch, var_len, time_len, 1450)\n",
    "    loss = loss.swapaxes(1, 2)\n",
    "    # loss.shape = (batch, var_len, time_len)\n",
    "    loss = torch.mean(loss, dim=-1)\n",
    "     # loss.shape = (var_len, batch, time_len)\n",
    "    loss = loss.swapaxes(0, 1)\n",
    "\n",
    "\n",
    "    src_seq.cpu().detach()\n",
    "    tgt_seq.cpu().detach()\n",
    "    src.cpu().detach()\n",
    "    tgt.cpu().detach()\n",
    "\n",
    "    label.cpu().detach()\n",
    "    predict.cpu().detach()\n",
    "    loss = loss.cpu().detach()\n",
    "    \n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
